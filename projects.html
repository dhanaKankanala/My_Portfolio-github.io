<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
-->
<html>

<head>
	<title>Projects</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<style>
		ul {
			list-style-type: none;
			padding-left: 0;
		}
	</style>
</head>

<body class="is-preload">

	<div id="wrapper">
		<header id="header">
			<a href="index.html" class="logo">Projects</a>
		</header>

		<nav id="nav">
			<ul class="links">
				<li><a href="index.html">About Me</a></li>
				<li class="active"><a href="projects.html">Projects</a></li>
				<!-- <li><a href="resume.html">Resume</a></li>
					<li><a href="experiences.html">Experiences</a></li>
					<li><a href="Achievement.html">Achievements</a></li>
					<li><a href="fearured.html">Featured</a></li> -->

			</ul>
			<ul class="icons">
				<li><a href="https://github.com/dhanaKankanala" class="icon brands fa-github"><span
							class="label">GitHub</span></a></li>
				<li><a href="https://www.linkedin.com/in/dhanakankanala/" class="icon brands alt fa-linkedin"><span
							class="label">LinkedIn</span></a></li>


			</ul>
		</nav>

		<!-- Main -->
		<div id="main">

			<section class="post">
				<!-- Project 1: Walk Signal Project -->
				<section>
					<header class="major">
						<h1>Leveraging machine learning in the development of wearable sensors for physical
							rehabilitation</h1>
					</header>
					<a href="#" class="image main"><img src="Dhana Images/Wearable Sensor.png"
							alt="Wearable Sensor Project" /></a>
					<h3>Problem:</h3>
					<p>Traditional rehabilitation relies on brief clinical observations, which may miss subtle gait
						variations essential for recovery. This lack of continuous monitoring makes it difficult to
						track progress accurately, detect mobility impairments early, and tailor rehabilitation
						strategies. Existing gait analysis methods are often costly, intrusive, or restricted to lab
						environments, limiting their effectiveness for real-world applications. Without a data-driven,
						accessible solution, individuals undergoing rehabilitation may face delayed adjustments in
						therapy, slowing down their recovery.</p>
					<ul><h3>Solution:</h3>
					<li>
						To address the limitations of traditional gait monitoring, we developed a wearable sensor-based
						system that integrates machine learning to analyze gait patterns and classify walking
						activities. The system captures resistance data from sensors embedded in footwear, ensuring
						structured and consistent data collection across different movement patterns.</li>

					<li>The data is filtered to reduce teh noise and then key step features are extracted. Train the
						machine learning models to classify the different walking activities
						accurately. Semi-supervised learning enhances the modelâ€™s ability to generalize to new data,
						while synthetic data generation (GANs) helps address data limitations.</li>

					<li>The project aims to provide real-time gait monitoring.So, currently we are developing a mobile
						application that
						connects to the sensor system via Bluetooth and Firebase. This ongoing work focuses on enabling
						seamless data transmission and visualization, making gait tracking more accessible and
						data-driven for rehabilitation and mobility assessment.
					</li>
				</ul>
					<h3>Role:</h3>
					<p>This is a collaborative project and I handled the machine learning development, including model
						training, data processing, and
						optimization. I communicate project updates and results to non-technical team members, ensuring
						alignment and clarity across the collaboration.</p>
					<h3>Tools & Languages Used:</h3>
					<ul>
						<li><strong>Programming & Data Processing:</strong>Python, Pandas, NumPy, Scikit-learn</li>
						<li><strong>Machine Learning: Random Forest, SVM, Logistic Regression, Semi-Supervised Learning</strong></li>
						<li><strong>Data Visualization: Power BI, Matplotlib, Excel</strong></li>
						<li><strong>Hardware & Storage: Arduino, Bluetooth, Firebase</strong></li>
					</ul>

					<ul class="actions">
						<li><a href="WearableSensor_poster.pdf" class="button primary" target="_blank">Poster</a></li>
					</ul>


					</ul>
				</section>

				<!-- Project 2: VN-Solver -->
				<section>
					<header class="major">
						<h1>VN-Solver: Vision-based Neural Solver using PointNet to solve Combinatorial Optimization
							over Graphs</h1>
					</header>
					<a href="#" class="image main"><img src="Dhana Images/Vn-Solver image.png"
							alt="ChatBotApplication" /></a>
					<h3>Problem:</h3>
					<p> Traditional combinatorial optimization solvers rely on matrix-based representations, which can
						be complex and computationally expensive. Recognizing patterns in graphs visually is often more
						intuitive, yet existing approaches do not fully leverage spatial graph structures. This project
						introduces a novel approach to solving the Hamiltonian Cycle Problem by converting graphs into
						3D point clouds, enabling neural networks to process and classify them based on their structural
						properties. </p>
					<ul><h3>Solution:</h3>
					<li>VN-Solver transforms 2D graphs into 3D point clouds using different graph embedding techniques,
						such as circular, spiral, and random layouts. This conversion preserves spatial relationships
						between nodes and edges, allowing for enhanced feature extraction.</li>
					<li><strong>Graph-to-Point Cloud Conversion: </strong> Transformed 2D graphs into 3D point clouds using circular,
						spiral, and random graph embeddings.</li>
					<li><strong>Feature Extraction & Representation: </strong> Captured node positions, edge relationships, and graph
						properties for enhanced classification.</li>
					<li><strong>Graph Classification with PointNet: </strong> Applied PointNet to process unordered point sets and classify
						graphs as Hamiltonian or non-Hamiltonian.</li>
					<li><strong>Performance Evaluation:</strong> Tested across different graph embeddings to assess accuracy and
						robustness.</li>
					</ul>
					<h3>Role:</h3>
					<p>This is an individual project and I developed the graph-to-3D point cloud transformation
						pipeline, implemented PointNet, and conducted experiments. Utilized GPU to process large
						datasets. </p>
					<h3>Tools & Languages Used:</h3>
					<ul>
						<li><strong>Programming & ML:</strong> Python,TensorFlow,Pytorch,Scikit-Learn</li>
						<li><strong>Graph & 3D Processing:</strong> Networkx, Open3D, NumPy, Pytcloud </li>
						<li><strong>data Handling & Visualization:</strong> Pandas, Matplotlib, Seaborn, MeshLab</li>
					</ul>
					<ul class="actions">
						<li><a href="https://github.com/dhanaKankanala/PointNet_RGB_VN_Solver" class="button primary" target="_blank">Github</a></li>
						<li><a href="vn_solver_final.pdf" class="button primary" target="_blank" download>Document</a></li>
						<li><a href="Vn_solver_poster.pdf" class="button primary" target="_blank">Poster</a></li>
					</ul>
				</section>

				<hr />

				<!-- Project 3 -->
				<section>
					<header class="major">
						<h1>Automatic Piano Music Generation Using Neural Networks</h1>
					</header>
					<a href="#" class="image main"><img src="Dhana Images/music_generation.jpg"
							alt="Music Generation" /></a>
					<h3>Problem:</h3>
					<p>Traditional music composition requires extensive human expertise and creativity. Automating
						music generation using artificial intelligence presents a challenge in producing expressive and
						well-structured compositions that capture the distinctive characteristics of musical
						instruments. This project aims to generate piano-based music using deep learning models while
						addressing challenges like data sparsity, overfitting, and capturing long-term dependencies in
						music patterns. </p>
					<ul> <h3>Solution:</h3>
						<li> <strong>Data Collection & Preprocessing:</strong> MIDI files from various artists were collected and parsed
							using the music21 library to extract piano notes, chords, and octaves.</li>
						<li> <strong>Feature Engineering:</strong> Notes were converted into numerical sequences for deep learning model
							training. Data sparsity was addressed by filtering low-frequency notes.</li>
						<li> <strong>Model Development:</strong> Implemented Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU)
							networks to generate music sequences.</li>
						<li> <strong>Training & Evaluation:</strong> Trained models on sequential MIDI data, tuning hyperparameters and
							optimizing for improved coherence and diversity in music generation.</li>
						<li> <strong>Music Generation & Output:</strong> Generated new music by iteratively predicting the next note in a
							sequence, composing new melodies based on trained models.</li>
						</ul>
						<h3>Role:</h3>
						<p>This is an individual project and I developed the graph-to-3D point cloud transformation
							pipeline, implemented PointNet, and conducted experiments. Utilized GPU to process large
							datasets. </p>
						<h3>Tools & Languages Used:</h3>
						<ul>
							<li><strong>Data Handling:</strong>music21, MIDI Dataset,glob, os</li>
							<li><strong>Data Processing:</strong> TensorFlow, Keras, Numpy, Pandas </li>
							<li><strong>Modeling & Optimization:</strong> LSTM, GRU, Adamax Optimizer </li>
						</ul>
						<ul class="actions">
							<li><a href="https://github.com/dhanaKankanala/Music_Generation" class="button primary" target="_blank">Github</a>
								<li><a href="MusicGenerationProject _Report.docx.pdf" class="button primary" target="_blank" download>Document</a></li>
							</li>
						</ul>
				</section>
			</section>

		</div>


		</section>
		</footer>
		</footer>

		<!-- Copyright -->
		<div id="copyright">
			<ul>
				<li>&copy; Dhana Lakshmi Kankanala </li>
			</ul>
		</div>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

</body>

</html>